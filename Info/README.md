# SDS25_MLOps-Lecture-4




# Feature Selection Techniques in Machine Learning - Practice

This exercise involves the implementation of different feature selection techniques on two different datasets. Feature selection is an important step in machine learning that aims to select the most relevant features from a given dataset. Through this exercise, we aim to explore and understand various feature selection techniques and their impact on model performance.

### Getting Started

To get started with the project, follow the steps below:

1. Clone the repository:

```bash
git clone https://github.com/saoter/SDS25_MLOps-Lecture-4
```

2. Open the `Feature_Selection_with_Accuracy.ipynb` notebook in your code editor.

3. Follow the instructions in the notebook to implement and explore different feature selection techniques.

### Project Overview

The notebook provides practice exercises for different feature selection techniques. The exercises include the following techniques:

1. Filter Methods: Implementing statistical tests such as correlation coefficient, Variance Threshold, Chi-Square, Information Gain and to rank features.
2. Wrapper Methods: Implementing techniques like Forward Selection, Backward Elimination and Exhaustive Feature Selection to select features based on model performance.
3. Embedded Methods: Implementing techniques like Regularization to select features during the model training process.
4. Permutation Methods

Each exercise includes code snippets, and sample datasets to practice and gain hands-on experience with feature selection techniques.


